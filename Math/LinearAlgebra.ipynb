{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Notes\n",
    "* All of linear algebra can be completed with two operations: vector addition and vector multiplication.\n",
    "* All vectors can be represented as scalar multiples of the basis vectors *i* and *j*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4]"
     ]
    }
   ],
   "source": [
    "\n",
    "# transpose and inverse\n",
    "# row echelon form\n",
    "# - https://en.wikipedia.org/wiki/Row_echelon_form\n",
    "# go through julia website\n",
    "# - https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/\n",
    "# add in latex equations\n",
    "\n",
    "A = [-1 1; 2 -1; 3 2]\n",
    "B = [1 0 -2; 0 1 2]\n",
    "\n",
    "A * B\n",
    "\n",
    "\n",
    "using LinearAlgebra\n",
    "\n",
    "# Vector addition.\n",
    "[1, 2] + [3, 4]\n",
    "\n",
    "# Vector scaling.\n",
    "[4, 6] * 2\n",
    "\n",
    "# Basis vectors.\n",
    "i = [1, 0]\n",
    "j = [0, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$\\mathbf{A} \\cdot \\mathbf{B}$: The dot product of matrices $\\mathbf{A}$ and $\\mathbf{B}$\n",
    "\n",
    "$\\mathbf{A} \\times \\mathbf{B}$: The cross product of matrices $\\mathbf{A}$ and $\\mathbf{B}$\n",
    "\n",
    "$\\mathbf{A}^T$: The transpose of matrix $\\mathbf{A}$\n",
    "\n",
    "$\\text{det}(\\mathbf{A})$: The determinant of matrix $\\mathbf{A}$\n",
    "\n",
    "$\\text{rank}(\\mathbf{A})$: The rank of matrix $\\mathbf{A}$\n",
    "\n",
    "$\\text{tr}(\\mathbf{A})$: The trace of matrix $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{A}^{-1}$: The inverse of matrix $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{Ax} = \\mathbf{b}$: A system of linear equations where $\\mathbf{A}$ is a matrix, $\\mathbf{x}$ is a column vector of variables, and $\\mathbf{b}$ is a column vector of constants\n",
    "\n",
    "$\\mathbf{x}^T\\mathbf{y}$: The dot product of column vectors $\\mathbf{x}$ and $\\mathbf{y}$\n",
    "\n",
    "$\\mathbf{x} \\cdot \\mathbf{y}$: The inner product of column vectors $\\mathbf{x}$ and $\\mathbf{y}$\n",
    "\n",
    "$|\\mathbf{x}|$: The norm of column vector $\\mathbf{x}$\n",
    "\n",
    "$\\mathbf{I}$: The identity matrix\n",
    "\n",
    "$\\mathbf{0}$: The zero matrix\n",
    "\n",
    "$\\text{span}{\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n}$: The span of column vectors $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$\n",
    "\n",
    "$\\text{null}(\\mathbf{A})$: The null space of matrix $\\mathbf{A}$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Transformations\n",
    "* Linear transformation is the process of multiplying vectors by a matrix in order to transform them into new vectors.\n",
    "* Linear transformation can be thought of as a way to move around space. Every time that you see a matrix you can interpret it as a transformation of space.\n",
    "    * For example, rotating the standard 2D grid by 45 degrees. \n",
    "* The linear transformation of any vector can be described/calculated in terms of how the basis vectors *i* and *j* are transformed by the linear transformation.\n",
    "* Matrices are the language that describes linear transformation.\n",
    "    * Columns of the matrix represent how the basis vectors are transformed, they can be thought of as the coordinates of the transformed basis vectors.\n",
    "    * You can transform vectors between dimensions with nonsquare matrices.\n",
    "* Types of linear transformations: rotate, reflect, scale, shear, project.\n",
    "* Matrix multiplication stretches or squeezes the size of the grid, this degree of stretch/squeeze is encoded in the determinant.\n",
    "    * This stretch/squeeze can be represented by how much area the basis vectors take up after transformation (by default 1i * 1j = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [2, 2]\n",
    "\n",
    "# Reflection in the y-axis.\n",
    "A = [-1 0; 0 1]\n",
    "A * vec\n",
    "\n",
    "# Reflection in the x-axis.\n",
    "A = [1 0; 0 -1]\n",
    "A * vec\n",
    "\n",
    "# Horizontal expansion.\n",
    "A = [2 0; 0 1]\n",
    "A * vec\n",
    "\n",
    "# Horizontal shear.\n",
    "A = [1 4; 0 1]\n",
    "A * vec\n",
    "\n",
    "# Transforming a vector from 2d to 3d space with a nonsquare matrix.\n",
    "A = [1 2; 3 4; 5 6]\n",
    "A * vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span and Linear Independence\n",
    "* **Vector Space** = Set of vectors {v1, v2, ..., vn} along with two operations, vector addition and scalar multiplication.\n",
    "* **Span** = Given a set of vectors {v1, v2, ..., vn} in a vector space V, the span is the set of all linear combinations of the vectors. \n",
    "    * The span is itself a vector space that represents all possible linear combinations of the given vectors.\n",
    "    * The dimension of the span equals the number of vectors in the vector space unless two of the vectors are linearly dependent (fall on the same line).\n",
    "* **Spanning Set** = Set of vectors that can be combined linearly to produce any vector in the vector space. A set of vectors that spans the entire vector space.\n",
    "* **Linear Independence** = A set of vectors is linearly independent if no vector in the set can be expressed as a linear combination of other vectors in the set.\n",
    "* **Basis** = The basis for a vector space is the set of linearly independent vectors that can be used to represent any vector in a vector space V.\n",
    "    * A vector space may have many different bases, but all bases have the same number of vectors, which is the dimension of the vector space.\n",
    "    * For example, the basis of 3D space is 3.\n",
    "* **Dimension** = Number of vectors in the basis.\n",
    "    * The dimension of any span equals the number of vectors in the span, unless two of the vectors are linearly dependent (fall on the same line).\n",
    "* **Rank** = Number of dimensions in the output of a transformation.\n",
    "    * A linear transformation that transforms space to a line has rank 1.\n",
    "    * A linear transformation that transforms space to a plane has rank 2.\n",
    "* **Column Space** = Span of the vectors that make up all columns in a matrix.\n",
    "* **Row Space** = Span of the vectors that make up all rows in a matrix.\n",
    "* **Null Space** = All possible solutions to the equation *Ax* = 0.\n",
    "    * All vectors *x* that become null (land on the zero vector) when transformed by *A*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any vector in the span of two vectors can be expressed as a linear combination\n",
    "# of the two vectors. For example, [2, 3, 0] is in the span of [1, 0, 0] and [0, 1, 0].\n",
    "[2, 3, 0] == 2 * [1, 0, 0] + 3 * [0, 1, 0]\n",
    "\n",
    "# The basis for 3D space i, j, k that can be used to represent any vector in 3D space.\n",
    "# Because there are 3 vectors, the dimension of the space is 3.\n",
    "i = [1, 0, 0]\n",
    "j = [0, 1, 0]\n",
    "k = [0, 0, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product \n",
    "* **Dot Product** = Length vector A * length vector B * cos(angle between the vectors).\n",
    "    * Geometrically, the dot product is equivalent to projecting one vector onto another, taking the length of the projection, and multiplying it by the length of the other vector.\n",
    "    * When the vectors point in the same direction, the projection and thus the dot product are positive.\n",
    "    * When the vectors point in opposite directions the dot product is negative.\n",
    "    * When the vectors are perpendicular (orthogonal), the projection onto the other vector has a length of 0, thus the dot product is 0.\n",
    "    * The dot product of a vector with itself is equal to the square of its magnitude (length).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dot Product\n",
    "A = [1, 4, 2]\n",
    "B = [2, 4, 2]\n",
    "\n",
    "# The dot product is calculated as the sum of the products of the corresponding\n",
    "# entries of the two vectors \n",
    "(1 * 2) + (4 * 4) + (2 * 2)\n",
    "dot(A, B)\n",
    "\n",
    "# The dot product of a vector with itself is equal to the square of its magnitude\n",
    "# (length). The length of the vector [2, 2] is 2.82.\n",
    "C = [2, 2]\n",
    "sqrt(dot(C, C))\n",
    "\n",
    "# The dot product of orthogonal vectors is 0.\n",
    "A = [10, 0]\n",
    "B = [0, 10]\n",
    "dot(A, B)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cross Product\n",
    "* **Cross Product** = Takes two vectors and produces a third vector that is orthogonal to both of the original vectors.\n",
    "    * The cross product, v x w is the area of the parallelogram formed by the two vectors\n",
    "    * The cross product of a vector with itself is 0. \n",
    "    * The cross product is simply the determinant of the matrix created by combining vectors v and w, this is because the determinant is a measure of how much the area changes as a result of transformation, and this area is the area of the parallelogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = [1, 4, 2]\n",
    "B = [2, 4, 2]\n",
    "\n",
    "# Formula for calculating the cross product.\n",
    "[A[2] * B[3] - A[3] * B[2], A[3] * B[1] - A[1] * B[3], A[1] * B[2] - A[2] * B[1]]\n",
    "cross(A, B)\n",
    "\n",
    "# The cross product of A and B is orthogonal to both A and B.\n",
    "dot(cross(A, B), A)\n",
    "dot(cross(A, B), B)\n",
    "\n",
    "# The cross product of a vector with itself is 0.\n",
    "cross(A, A)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinants\n",
    "* **Determinant** = Scalar value that measures how much the area of a vector space changes as a result of transformation.\n",
    "    * Can only be computed for square matrices.\n",
    "    * Negative determinants represent a flip of orientation.\n",
    "    * When the determinant is 0, *i* has been transformed so it is a linear combination of *j* (on the same line). The area of the grid is now 0, thus the determinant is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The determinant of a 2x2 matrix [a b; c d] is given by the formula ad - bc.\n",
    "A = [1 2; 3 4]\n",
    "1 * 4 - 2 * 3\n",
    "det(A)\n",
    "\n",
    "# The determinant of a horizontal expansion by a factor of 2 is simply 2. \n",
    "A = [2 0; 0 1]\n",
    "det(A)\n",
    "\n",
    "# The determinant of larger matrices can be manually calculated using Laplace expansion.\n",
    "A = [1 2 3; 4 1 6; 7 8 1]\n",
    "det(A)\n",
    "\n",
    "# The determinant of a matrix is also the product of the eigenvalues of the matrix.\n",
    "vals = eigvals(A)\n",
    "vals[1] * vals[2] * vals[3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "* Matrix multiplication is simply a composition of linear transformations. \n",
    "    * Each matrix represents a linear transformation, and the multiplication of both matrices tells you what happens to the basis vectors when both linear transformations are applied.\n",
    "    * For example, two matrices may represent a grid being rotated 90 degrees and then being sheared.\n",
    "    * The order in which matrices are multiplied matters, a 90 degree rotation followed by a shear results in a different matrix than a shear followed by a 90 degree rotation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [2, 2]\n",
    "\n",
    "# Reflect over the y-axis and then stretch in the horizontal direction.\n",
    "A = [-1 0; 0 1]\n",
    "B = [2 0; 0 1]\n",
    "A * B * vec "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems of Linear Equations\n",
    "* The geometric interpretation of solving the fundamental equation *Ax* = *b* is the following: We are looking for a matrix *A* that transforms vector *x* into vector *b*.\n",
    "    * *Ax* = *b* is solving for which original vector *x* is stretched to *b* when the matrix *A* transforms the space.\n",
    "* *A* is a coefficient matrix, *x* is the vector of variables that we want to solve for, and *b* is vector of constants on the right hand side of the equation. \n",
    "* If the matrix *A* is invertible (its determinant does not equal 0), then we can solve for *x* using the form: *x* = *A^(-1) * b*.\n",
    "    * If det(A) does not equal 0 than the columns are linearly dependent and the transformation using A does not squish all space into a lower dimension, thus there is only one vector *x* that can be transformed into vector *b* via *A*.\n",
    "    * If det(A) = 0 then the transformation from *A* squishes space into a lower dimension and it is likely that there is no solution. There will only be a solution if *b* falls upon the lower dimension line/plane/etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the system of equations:\n",
    "x + 2y + 2z = 5\n",
    "3x - 2y + z = -6\n",
    "2x + y - z = 1\n",
    "\n",
    "# This can be represented as:\n",
    "A = [1 2 2; 3 -2 1; 2 1 -1]\n",
    "x = [x, y, z]\n",
    "b = [5, -6, 1]\n",
    "\n",
    "# The vector x is solved for by multiplying the inverse of A by b.\n",
    "coefs = inv(A) * b\n",
    "\n",
    "# Check outputs.\n",
    "(1 * coefs[1]) + (2 * coefs[2]) + (2 * coefs[3])\n",
    "(3 * coefs[1]) + (-2 * coefs[2]) + (1 * coefs[3])\n",
    "(2 * coefs[1]) + (1 * coefs[2]) + (-1 * coefs[3])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors, Eigenvalues\n",
    "* **Eigenvector** = Vector that does not get knocked off its span (the 1D line that houses all scalar multiples of the vector) when a matrix transformation *A* is applied to the vector.\n",
    "    * *A* * *v* = *lambda* * *v* where *v* is the eigenvector and *lambda* is the eigenvalue.  \n",
    "* **Eigenvalue** = The factor with which the vector is stretched or squished during the transformation. \n",
    "* Eigenvectors can be used to scale down large matrices. If *M* is a large matrix, we can look for a vector *o* and a scalar *n* which can be used to generate *M*.\n",
    "    * *M* * *o* = *o* * *n* where *o* is the eigenvector and *n* is the eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 2; 3 4]\n",
    "\n",
    "# Find the eigenvectors and eigenvalues of A.\n",
    "eigvecs(A)\n",
    "eigvals(A)\n",
    "\n",
    "# For both eigenvectors and eigenvalues, A * eigvec = eigvec * eigval.\n",
    "A * eigvecs(A)[:, 1]\n",
    "eigvecs(A)[:, 1] * eigvals(A)[1]\n",
    "\n",
    "A * eigvecs(A)[:, 2]\n",
    "eigvecs(A)[:, 2] * eigvals(A)[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
