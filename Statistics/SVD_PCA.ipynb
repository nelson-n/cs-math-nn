{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "* Singular Value Decomposition (SVD)\n",
    "* SVD Coding Exercises\n",
    "* Principal Component Analysis (PCA)\n",
    "* PCA Coding Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "![](./NoteFiles/SVD1.png)\n",
    "![](./NoteFiles/SVD2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SVD Coding Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = ''\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#===============================================================================\n",
    "# Testing SVD Theory on a Model Matrix\n",
    "#===============================================================================\n",
    "\n",
    "## Setting some definitions:\n",
    "# X = input matrix\n",
    "# U = U matrix (great definition I know)\n",
    "# S = Sigma matrix (diagonal matrix of ranks)\n",
    "# Vt = Transposed V matrix\n",
    "# In theory, X = USVt\n",
    "\n",
    "# Init model matrix.\n",
    "X = np.matrix([\n",
    "    [2, 4, 6],\n",
    "    [5, 1, 3],\n",
    "    [2, 9, 4],\n",
    "    [7, 3, 1],\n",
    "    [6, 3, 4]\n",
    "])\n",
    "\n",
    "# Compute SVD.\n",
    "U, S, Vt = np.linalg.svd(X)\n",
    "\n",
    "# Convert sigma matrix from array to diag matrix and if necessary add rows of\n",
    "# zeroes to the sigma matrix (for the case that num rows X > num cols X) to\n",
    "# create an S long (Sl) version of the sigma matrix.\n",
    "S = np.diag(S)\n",
    "\n",
    "if X.shape[0] > X.shape[1]:\n",
    "    Sl = np.vstack([S, np.zeros([X.shape[0] - len(S), X.shape[1]])])\n",
    "\n",
    "# Test that the SVD is not a farce! X = USVt\n",
    "np.dot(U, np.dot(Sl, Vt))\n",
    "\n",
    "# Now testing some of the intuition of the SVD.\n",
    "# XtX = the correlation matrix among the columns of X, i.e. the inner products\n",
    "# of the input data itself. Large values represent similarity and small values\n",
    "# represent places that are more orthagonal (less similar). \n",
    "Xt = np.transpose(X)\n",
    "XtX = np.dot(Xt, X)\n",
    "\n",
    "# Given the definition of the SVD as X = USVt, we can plug USVt in for X in \n",
    "# the correlation matrix XtX and perform the following calculation.\n",
    "# XtX = VSUtUSVt = VS^2Vt\n",
    "\n",
    "# VS^2Vt is the eigenvalue decomposition of the correlation matrix XtX where\n",
    "# S^2 are the eigenvalues of XtX and V are the eigenvectors of XtX.\n",
    "\n",
    "# S^2 = eigenvalues of XtX\n",
    "np.square(S)\n",
    "np.linalg.eig(XtX)[0]\n",
    "\n",
    "# V = eigenvectors of XtX\n",
    "V = np.linalg.eig(XtX)[1]\n",
    "\n",
    "# Thus, in the singular value decomposition USVt, V is just the eigenvectors\n",
    "# of the correlation matrix X and S (sigma) is the square root of the \n",
    "# eigenvalues of the same correlation matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Statistics/Data/demo.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m data_dir \u001b[39m=\u001b[39m root_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mStatistics/Data/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[39m# Load image, convert to grayscale (1 channel), view image.\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m img \u001b[39m=\u001b[39m imread(data_dir \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mdemo.jpeg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     77\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(img, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     79\u001b[0m plt\u001b[39m.\u001b[39mimshow(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/image.py:1563\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(parse\u001b[39m.\u001b[39murlparse(fname)\u001b[39m.\u001b[39mscheme) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1557\u001b[0m     \u001b[39m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         )\n\u001b[0;32m-> 1563\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[1;32m   1564\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/PIL/Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3215\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3217\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3218\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3219\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Statistics/Data/demo.jpeg'"
     ]
    }
   ],
   "source": [
    "#===============================================================================\n",
    "# Testing Some Image Compression with SVD\n",
    "#===============================================================================\n",
    "\n",
    "# Set path to demo image.\n",
    "data_dir = root_dir + 'Statistics/Data/'\n",
    "\n",
    "# Load image, convert to grayscale (1 channel), view image.\n",
    "img = imread(data_dir + 'demo.jpeg')\n",
    "X = np.mean(img, -1)\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.show()\n",
    "\n",
    "# Perform SVD on image X using the economy SVD indicated with the full_matrices\n",
    "# argument. This cuts off the zero rows of the sigma matrix.\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices = False)\n",
    "S = np.diag(S)\n",
    "\n",
    "# Subset to the first 5 rows/cols of the U, S, Vt matrices and reconstruct a\n",
    "# compressed version of X using the fancy @ matmul operator. Then view compressed image.\n",
    "i = 5\n",
    "X_comp = U[:, :i] @ S[0:i, :i] @ Vt[:i, :]\n",
    "\n",
    "plt.imshow(X_comp)\n",
    "plt.show()\n",
    "\n",
    "# Subset to the first 20 rows/cols.\n",
    "i = 20\n",
    "X_comp = U[:, :i] @ S[0:i, :i] @ Vt[:i, :]\n",
    "\n",
    "plt.imshow(X_comp)\n",
    "plt.show()\n",
    "\n",
    "# Subset to the first 100 rows/cols.\n",
    "i = 100\n",
    "X_comp = U[:, :i] @ S[0:i, :i] @ Vt[:i, :]\n",
    "\n",
    "plt.imshow(X_comp)\n",
    "plt.show()\n",
    "\n",
    "# Plot the eigenvalues (square root technically) to see where the information\n",
    "# content of the image starts to fall off (plotting sigma matrix).\n",
    "plt.figure(1)\n",
    "plt.semilogy(S)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Using SVD on MNIST Dataset\n",
    "#===============================================================================\n",
    "\n",
    "# Set path to MNIST images.\n",
    "data_dir = root_dir + '/NeuralNetworks/data/MNIST/'\n",
    "\n",
    "# Load MNIST images, the images are loaded as a [10000, 784] matrix with \n",
    "# 10000 images (rows) each with 28*28=784 pixels (images and black and white\n",
    "# so there is only one channel, thus we get a nice 2D matrix).\n",
    "imgs  = gzip.open(data_dir + 't10k-images-idx3-ubyte.gz', 'rb').read()\n",
    "imgs = np.frombuffer(imgs, dtype=np.uint8, offset=16).reshape(-1, 28*28)/255\n",
    "\n",
    "# Select first image in set and reshape to a [28, 28] matrix, then view the image.\n",
    "img = imgs[1,:].reshape(28, 28)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# We want the handwritten digits to be columnwise, so transpose matrix.\n",
    "X = np.transpose(imgs)\n",
    "\n",
    "# Calculate economy SVD.\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices = False)\n",
    "\n",
    "# Plot the sigmas. Note that the energy/information does not fall off until\n",
    "# 650+ pixels, making the SVD or PCA of this dataset not particularly useful.\n",
    "plt.figure(1)\n",
    "plt.semilogy(S)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Visualizing the Accuracy of Rank-K Approximations of an Images Using SVD\n",
    "#===============================================================================\n",
    "\n",
    "# This exercise uses the \"Eigenfaces\" dataset.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.fetch_olivetti_faces()\n",
    "images = data.images\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Select a random image from the dataset, and create a rank-k approximation of \n",
    "# it using k = [10, 20, 30, 40]. \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "image = images[100]\n",
    "\n",
    "k_approxs = []\n",
    "\n",
    "for k in [10, 20, 30, 40]:\n",
    "\n",
    "    # Compute the SVD of M.\n",
    "    U, S, Vt = np.linalg.svd(image, full_matrices=False)\n",
    "\n",
    "    # Take the first k columns of U and the first k rows of Vt.\n",
    "    Uk = U[:, :k]\n",
    "    Sk = np.diag(S[:k])\n",
    "    Vtk = Vt[:k, :]\n",
    "\n",
    "    # Compute the rank-k approximation of M.\n",
    "    Mk = Uk @ Sk @ Vtk\n",
    "\n",
    "    k_approxs.append(Mk)\n",
    "\n",
    "# Plot the images. \n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(k_approxs[i], cmap='gray')\n",
    "    ax.set_title(f'k = {i * 10 + 10}')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "![](./NoteFiles/PCA1.png)\n",
    "![](./NoteFiles/PCA2.png)\n",
    "![](./NoteFiles/PCA3.png)\n",
    "![](./NoteFiles/PCA4.png)\n",
    "![](./NoteFiles/PCA5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Coding Exercises\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "===============================================================================\n",
    "# Testing PCA Theory on a Model Matrix\n",
    "#===============================================================================\n",
    "\n",
    "# PCA intuitive explanation: a hierarchical coordinate system that captures\n",
    "# the directions in an input data matrix X that explain the most variance \n",
    "# in X.\n",
    "\n",
    "# Using the same input X matrix as in the SVD theory section above. First \n",
    "# calculate a mean centered matrix B by substracting mean of the rows of X\n",
    "# from X.\n",
    "X_mean = np.mean(X, axis = 0)\n",
    "B = X - X_mean\n",
    "\n",
    "# Calculate covariance matrix.\n",
    "cov = np.cov(B, rowvar = False)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors of the covariance matrix, then order\n",
    "# them by the size of the eigenvalues.\n",
    "eigval, eigvec = np.linalg.eigh(cov)\n",
    "index = np.argsort(eigval)[::-1]\n",
    "eigvec = eigvec[:, index]\n",
    "eigval = eigval[index]\n",
    "\n",
    "# This is equivalent to scaling down a large matrix using eigenvectors. If M \n",
    "# is a large matrix we can look for a vector o and a scalar n such that \n",
    "# M * o = n * o where o are eigenvectors and n are eigenvalues. By the same \n",
    "# logic, in the PCA case: cov * eigvec = eigval * eigvec\n",
    "cov @ eigvec\n",
    "eigval * eigvec\n",
    "\n",
    "# In PCA, T = BV where T are the principal components and V are the eigenvectors\n",
    "# (called the loadings in PCA).\n",
    "T = B @ eigvec\n",
    "\n",
    "# Putting it all together in a function that calculates PCA given an input\n",
    "# matrix X.\n",
    "def PCA(X):\n",
    "\n",
    "\tX_mean = np.mean(X, axis = 0)\n",
    "\tB = X - X_mean\n",
    "\n",
    "\tcov = np.cov(B, rowvar = False)\n",
    "\n",
    "\teigval, eigvec = np.linalg.eigh(cov)\n",
    "\tindex = np.argsort(eigval)[::-1]\n",
    "\teigvec = eigvec[:, index]\n",
    "\teigval = eigval[index]\n",
    "\n",
    "\tT = B @ eigvec\n",
    "\n",
    "\treturn T\n",
    "\n",
    "# Using SVD, one can compute B = USVt, which allows for the conversion between\n",
    "# SVD values and PCA loadings.\n",
    "U, S, Vt = np.linalg.svd(B, full_matrices = False)\n",
    "S = np.diag(S)\n",
    "\n",
    "# Plugging in USVt for B in the PCA equation: T = BV.\n",
    "T_alt = U @ S @ Vt @ eigvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Using PCA on a Transformed Matrix with Known Properties\n",
    "#===============================================================================\n",
    "\n",
    "# We are going to take a matrix with normal gaussian properties centered at\n",
    "# 0, 0 and then transform it to give it known properties, we will then test\n",
    "# whether PCA is able to find these properties. This demo is inspired by\n",
    "# Steve Brunton's series on PCA.\n",
    "\n",
    "# Data will be centered at 2, 1.\n",
    "center = np.array([2, 1])\n",
    "\n",
    "# Data will be stretched by a factor of 2 in the x-direction and compressed\n",
    "# by a factor of 0.5 in the y-direction.\n",
    "stretch = np.array([2, 0.5])\n",
    "\n",
    "# Data will be rotated by a factor of pi/3 using the rotation matrix.\n",
    "theta = np.pi/3\n",
    "\n",
    "rotate = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                   [np.sin(theta), np.cos(theta)]]) \n",
    "\n",
    "# Create transformed matrix with 10,000 data points.\n",
    "X = rotate @ np.diag(stretch) @ np.random.randn(2, 10000) + np.diag(center) @ np.ones([2, 10000])\n",
    "\n",
    "# Plot X to make sure we did the transformations correctly.\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(111)\n",
    "plt.scatter(X[0,:], X[1,:], s=2)\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean centered matrix B.\n",
    "X_mean = np.mean(X, axis = 1)\n",
    "B = X - np.tile(X_mean, (10000, 1)).T\n",
    "\n",
    "# Check that mean centered matrix B looks correct.\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(111)\n",
    "plt.scatter(B[0,:], B[1,:], s=2)\n",
    "plt.show()\n",
    "\n",
    "# Find principal components via SVD.\n",
    "U, S, Vt = np.linalg.svd(B / np.sqrt(10000), full_matrices = False)\n",
    "\n",
    "# The resultant sigma matrix S has values of ~2 and ~0.5 which tells you that\n",
    "# the first principal component has a lot of variance (the stretch of factor \n",
    "# 2 in the x-direction) and the second principal component has less variance\n",
    "# the compression of factor 0.5 in the y-direction.\n",
    "\n",
    "# The resultant U matrix tells us how the distribution is rotated. Note that\n",
    "# the transformation induced by the rotate matrix is the same as the U matrix.\n",
    "U\n",
    "rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Plot First Two Principal Components in Space\n",
    "#===============================================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# This example uses the sklearn cancer dataset. Principle components are plotted\n",
    "# after both calculating PCA by hand using SVD and using the sklearn.decomposition.PCA.\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "features = np.array(pd.DataFrame(cancer.data, columns=cancer.feature_names))\n",
    "labels = np.array(pd.DataFrame(cancer.target, columns=['label']))\n",
    "\n",
    "# Rescale features to be mean 0 and standard deviation 1.\n",
    "features = StandardScaler().fit_transform(features)\n",
    "\n",
    "# --- First 2 Principal Components using SVD ---\n",
    "\n",
    "U, S, Vt = np.linalg.svd(features, full_matrices=False)\n",
    "\n",
    "# Pull out the first two principle components, first two rows of the right \n",
    "# singular vectors Vt.\n",
    "PC2_SVD = np.array(Vt[:2, :])\n",
    "PC2_SVD = -PC2_SVD # Flip the sign to match the results from sklearn.\n",
    "\n",
    "# Project the features onto the first two principal components.\n",
    "Features2_SVD = features @ PC2_SVD.T\n",
    "\n",
    "# --- First 2 Principal Components using sklearn.decomposition.PCA ---\n",
    "\n",
    "PC2_sklearn = PCA(n_components=2)\n",
    "\n",
    "# Project the features onto the first two principal components.\n",
    "Features2_sklearn = PC2_sklearn.fit_transform(features)\n",
    "\n",
    "# Verify that the results are the same.\n",
    "print(\"Difference between Features2_SVD and Features2_sklearn:\" + str(np.sum(np.abs(Features2_sklearn - Features2_SVD)).round(5)))\n",
    "\n",
    "# Create scatterplots using both PCA methods.\n",
    "plt.scatter(Features2_SVD[:, 0], Features2_SVD[:, 1], c=labels)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('First 2 Principal Components using SVD')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(Features2_sklearn[:, 0], Features2_sklearn[:, 1], c=labels)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('First 2 Principal Components using sklearn.decomposition.PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
