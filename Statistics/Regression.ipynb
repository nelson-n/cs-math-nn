{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "- Linear Regression\n",
    "- Logit Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Interpretations of Linear Regression\n",
    "\n",
    "**Geometric Interpretation** = Find the coefficients of the line that minimizes the sum of the squared distances between the line and the points.\n",
    "**Statistic Interpretation** = Find the coefficients that give you the maximum likelihood of seeing the dataset.\n",
    "\n",
    "![](./NoteFiles/LinReg1.png)\n",
    "![](./NoteFiles/LinReg2.png)\n",
    "![](./NoteFiles/LinReg3.png)\n",
    "![](./NoteFiles/LinReg4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Gradient Descent to Linear Regression\n",
    "\n",
    "![](./NoteFiles/LinReg4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Linear Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "#==============================================================================\n",
    "# OLS Using Stochastic Gradient Descent\n",
    "#==============================================================================\n",
    "\n",
    "# Function for making an OLS prediction (yhat) given a matrix of covariates X,\n",
    "# a vector of true values y, and a list of coefficients.\n",
    "def predict_ols(Xy, coefficients):\n",
    "\n",
    "\tyhat = coefficients[0]\n",
    "\n",
    "\tfor i in range(len(Xy)-1):\n",
    "\t\tyhat += coefficients[i + 1] * Xy[i]\n",
    "\n",
    "\treturn yhat\n",
    "\n",
    "# Function for updating OLS coefficents using online SGD. Coefficients are\n",
    "# initiated to equal 0, one sample (row) of the training set is randomly\n",
    "# selected, the prediction error is calculated and scaled by the learning rate, \n",
    "# the intercept and coefficients are updated to minimize error.\n",
    "def coefficients_sgd(Xy_train, lr, epochs):\n",
    "\n",
    "\tcoef = [0.0 for i in range(len(Xy_train[0]))]\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\n",
    "\t\tfor row in random.sample(Xy_train, 1):\n",
    "\t\t\tyhat = predict_ols(row, coef)\n",
    "\t\t\terror = yhat - row[-1]\n",
    "\n",
    "\t\t\tcoef[0] = coef[0] - lr * error\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i+1] - lr * error * row[i]\n",
    "\n",
    "\treturn coef\n",
    "\n",
    "# Given a training dataset and a testing dataset, estimate coefficients via\n",
    "# SGD on the training dataset and use these coefficients to make OLS predictions\n",
    "# on the testing dataset.\n",
    "def linear_regression_sgd(train, test, lr, epochs):\n",
    "\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, lr, epochs)\n",
    "\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict_ols(row, coef)\n",
    "\t\tpredictions.append(yhat)\n",
    "\n",
    "\treturn(predictions)\n",
    "\n",
    "# Function for calculating root mean squared error.\n",
    "def rmse(actual, predicted):\n",
    "\n",
    "\tsum_error = 0.0\n",
    "\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tprediction_error = predicted[i] - actual[i]\n",
    "\t\tsum_error += (prediction_error ** 2)\n",
    "\n",
    "\tmean_error = sum_error / float(len(actual))\n",
    "\n",
    "\treturn math.sqrt(mean_error)\n",
    "\n",
    "# Synthetic dataset with expected intercept of 0 and coefficient of 2.\n",
    "dataset = [[i, 2*i+random.gauss(0, 0.1)] for i in range(0, 100)]\n",
    "lr = 0.00001\n",
    "epochs = 1000\n",
    "estimates = coefficients_sgd(dataset, lr, epochs)\n",
    "print(\"Estimated Beta0: %f\" % estimates[0])\n",
    "print(\"Estimated Beta1: %f\" % estimates[1])\n",
    "\n",
    "# Train and evaluate OLS coefficients on test set.\n",
    "train = [[i, 2*i+random.gauss(0, 0.1)] for i in range(0, 100)]\n",
    "test = [[i, 2*i+random.gauss(0, 0.1)] for i in range(102, 122)]\n",
    "lr = 0.0001\n",
    "epochs = 1000\n",
    "predicted = linear_regression_sgd(train, test, lr, epochs)\n",
    "actual = [t[-1] for t in test]\n",
    "print(\"RMSE: \", str(rmse(actual, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![](./NoteFiles/LogitReg1.png)\n",
    "![](./NoteFiles/LogitReg2.png)\n",
    "![](./NoteFiles/LogitReg3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Logit Using Stochastic Gradient Descent\n",
    "#==============================================================================\n",
    "\n",
    "# Testing SGD using logit instead of OLS. \n",
    "\n",
    "def predict_logit(Xy, coefficients):\n",
    "\n",
    "\tyhat = coefficients[0]\n",
    "\n",
    "\tfor i in range(len(Xy)-1):\n",
    "\t\tyhat += coefficients[i + 1] * Xy[i]\n",
    "\n",
    "\treturn 1.0 / (1.0 + math.exp(-yhat))\n",
    " \n",
    "def coefficients_sgd(Xy_train, lr, epochs):\n",
    "\n",
    "\tcoef = [0.0 for i in range(len(Xy_train[0]))]\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\n",
    "\t\tfor row in random.sample(Xy_train, 1):\n",
    "\t\t\tyhat = predict_logit(row, coef)\n",
    "\t\t\terror = row[-1] - yhat\n",
    "\n",
    "\t\t\tcoef[0] = coef[0] + lr * error * yhat * (1.0 - yhat)\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + lr * error * yhat * (1.0 - yhat) * row[i]\n",
    "\n",
    "\treturn coef\n",
    " \n",
    "def logistic_regression(train, test, lr, epochs):\n",
    "\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, lr, epochs)\n",
    "\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict_logit(row, coef)\n",
    "\t\tyhat = round(yhat)\n",
    "\t\tpredictions.append(yhat)\n",
    "\n",
    "\treturn(predictions)\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "\n",
    "\tcorrect = 0\n",
    "\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Synthetic dataset.\n",
    "dataset = [2*[random.gauss(0, 0.1)] for i in range(0, 500)]\n",
    "dataset = [[t[0], max(t[0]/abs(t[0]), 0.0)] for t in dataset]\n",
    "lr = 0.1\n",
    "epochs = 200\n",
    "coef = coefficients_sgd(dataset, lr, epochs)\n",
    "print(coef)\n",
    "\n",
    "# Train and evaluate logit coefficients on test set.\n",
    "train = [2*[random.gauss(0, 1)] for i in range(0, 500)]\n",
    "train = [[t[0],max(t[0]/abs(t[0]), 0.0)] for t in train]\n",
    "test = [2*[random.gauss(0, 1)] for i in range(0, 100)]\n",
    "test = [[t[0],max(t[0]/abs(t[0]), 0.0)] for t in test]\n",
    "lr = 0.1\n",
    "epochs = 200\n",
    "predicted = logistic_regression(train, test, lr, epochs)\n",
    "actual = [t[-1] for t in test]\n",
    "accuracy_metric(actual, predicted)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
