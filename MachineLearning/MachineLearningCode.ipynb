{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Many of the following code examples utilize the following cancer recognition dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "CancerDataset = datasets.load_breast_cancer()\n",
    "\n",
    "Features = pd.DataFrame(CancerDataset.data, columns = CancerDataset.feature_names)\n",
    "Labels = pd.DataFrame(CancerDataset.target, columns = ['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947275922671354"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "DecTreeModel = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "DecTree = DecTreeModel.fit(Features, Labels)\n",
    "\n",
    "Predictions = DecTree.predict(Features)\n",
    "\n",
    "sum(Predictions == Labels['label']) / len(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94736842, 0.94736842, 0.89473684, 0.94736842, 0.9122807 ,\n",
       "       0.94736842, 0.94736842, 0.89473684, 0.96491228, 0.96428571])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "DecTreeModel = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "KfoldDecTree = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "cross_val_score(DecTreeModel, Features, Labels['label'], cv = KfoldDecTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.85964912, 0.96491228, 0.9122807 , 0.98245614,\n",
       "       0.92982456, 0.94736842, 0.96491228, 0.96491228, 0.98214286])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestModel = RandomForestClassifier(n_estimators = 10, max_depth = 5)\n",
    "KfoldRandomForest = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "cross_val_score(RandomForestModel, Features, Labels['label'], cv = KfoldRandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "RegressionModel = LogisticRegression(max_iter = 100)\n",
    "Regression = RegressionModel.fit(Features, Labels['label'])\n",
    "\n",
    "Coefficients = Regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94736842, 0.92982456, 0.96491228, 0.98245614, 0.94736842,\n",
       "       0.94736842, 0.96491228, 0.92982456, 0.92982456, 0.89285714])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "DecTreeModel = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "AdaBoostModel = AdaBoostClassifier(estimator = DecTreeModel, n_estimators = 10, learning_rate = 1)\n",
    "KfoldAdaBoost = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "cross_val_score(AdaBoostModel, Features, Labels['label'], cv = KfoldAdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "* Given a square loss function: \n",
    "$$\\frac{1}{2}(\\sigma (w' \\cdot x) - y)^2$$\n",
    "\n",
    "* Where $\\sigma$ is the sigmoid activation function: \n",
    "$$\\frac{1}{(1 + e^{-x})}$$\n",
    "\n",
    "* And thus the gradient of the loss function with respect to the weights is:\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial f}{\\partial w} = (\\sigma(w' \\cdot x_i) - y_i) * \\sigma(w' \\cdot x_i) * (1 - \\sigma(w' \\cdot x_i)) * x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Learning rate.\n",
    "eta = 0.01\n",
    "\n",
    "# Generate true weights (w), observations (X), and labels (Y).\n",
    "w, X, Y = GenerateData(m)\n",
    "\n",
    "# Initialize weights.\n",
    "w_prime = np.zeros(10)\n",
    "\n",
    "gradient = np.zeros(10)\n",
    "\n",
    "for o in range(n_iters):\n",
    "\n",
    "    # Iterate through each data point in X, Y.\n",
    "    for i in range(m):\n",
    "\n",
    "        x_i = X[i]\n",
    "        y_i = Y[i]\n",
    "\n",
    "        gradient += (sigmoid(w_prime @ x_i) - y_i) * sigmoid(w_prime @ x_i) * (1 - sigmoid(w_prime @ x_i)) * x_i\n",
    "\n",
    "    # Calculate the gradient for the whole dataset as the average of the summed\n",
    "    # gradients from each data point.\n",
    "    gradient = gradient / m\n",
    "\n",
    "    w_prime = w_prime - eta * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "U, S, Vt = np.linalg.svd(Features, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Features = np.array(pd.DataFrame(cancer.data, columns=cancer.feature_names))\n",
    "Labels = np.array(pd.DataFrame(cancer.target, columns=['label']))\n",
    "\n",
    "# Rescale features to be mean 0 and standard deviation 1.\n",
    "Features = StandardScaler().fit_transform(Features)\n",
    "\n",
    "# Calculate the first two principal components.\n",
    "PC2 = PCA(n_components=2)\n",
    "\n",
    "# Project the dataset features onto the first two principal components.\n",
    "Features2 = PC2.fit_transform(Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def kmeans(X, k = 4, max_iter = 500, random_state=0):\n",
    "\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "      X: input data matrix, numpy array with shape (n * d), n: number of data points, d: feature dimension\n",
    "      k: number of clusters\n",
    "      max_iters: maximum iterations\n",
    "  Output:\n",
    "      clustering label for each data point\n",
    "  \"\"\"\n",
    "\n",
    "  assert len(X) > k, 'illegal inputs'\n",
    "  np.random.seed(random_state)\n",
    "\n",
    "  # Randomly select k data points as centers.\n",
    "  idx = np.random.choice(len(X), k, replace=False)\n",
    "  centers = X[idx]\n",
    "  print('Initial center observations: ', idx)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "\n",
    "    # Compute distance from each data point to centers.\n",
    "    H = distance.cdist(X, centers, 'euclidean')\n",
    "\n",
    "    # Create vector assigning each data point to the closest centroid.\n",
    "    CentroidNum = np.argmin(H, axis=1)\n",
    "\n",
    "    # Update the centroids as the average of all data points belonging to a given centroid.\n",
    "    for j in range(k):\n",
    "      centers[j] = np.mean(X[CentroidNum == j], axis=0)\n",
    "    \n",
    "  # Label each data point with the centroid it is closest to.\n",
    "  labels = CentroidNum \n",
    "\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Radial basis function kernel.\n",
    "def rbf_kernel(X, Xp, h):\n",
    "    # X: n*1 matrix\n",
    "    # Xp: m*1 matrix\n",
    "    # h: scalar value \n",
    "                \n",
    "    # Find the pairwise distance between X and Xp.\n",
    "    K = np.exp(-cdist(X, Xp)**2/(2*h**2))\n",
    "            \n",
    "    return K # n*m\n",
    "\n",
    "# Calculate h-parameter for the RBF kernel as the median of the pairwise distance of X\n",
    "# after removing diagonal terms which are all 0 (the distance of a point to itself is 0).\n",
    "def median_distance(X):\n",
    "    # X: n*1 matrix\n",
    "    h = np.median([distance.euclidean(X[i], X[j]) for i in range(len(X)) for j in range(len(X)) if i != j])\n",
    "    return h\n",
    "\n",
    "# Calculate kernel regression weights.\n",
    "def kernel_regression_fitting(xTrain, yTrain, h, beta=1):\n",
    "    # X: input data, numpy array, n*1\n",
    "    # Y: input labels, numpy array, n*1\n",
    "    W = np.linalg.inv(rbf_kernel(xTrain, xTrain, h) + beta * np.identity(len(xTrain))) @ yTrain\n",
    "    return W\n",
    "\n",
    "# Train kernel weights and predict labels for test data.\n",
    "def kernel_regression_fit_and_predict(xTrain, yTrain, xTest, h, beta):\n",
    "    \n",
    "    # Calculate kernel weights using training data.\n",
    "    W = kernel_regression_fitting(xTrain, yTrain, h, beta)\n",
    "    \n",
    "    # Compute the kernel matrix between xTrain and xTest.\n",
    "    K_xTrain_xTest = rbf_kernel(xTrain, xTest, h)\n",
    "   \n",
    "    # Predict the label of xTest using the kernel matrix and weights.\n",
    "    yPred = np.dot(K_xTrain_xTest.T, W)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
